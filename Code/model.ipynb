{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in c:\\users\\thanh\\anaconda3\\lib\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in c:\\users\\thanh\\anaconda3\\lib\\site-packages (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.layer import Convolutional, Pooling, FullyConnected, Dense, regularized_cross_entropy, lr_schedule\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def build_model(self, dataset_name):\n",
    "            self.add_layer(Convolutional(name='conv1', num_filters=32, stride=1, size=3, activation='relu'))\n",
    "            self.add_layer(Convolutional(name='conv2', num_filters=32, stride=1, size=3, activation='relu'))\n",
    "            self.add_layer(Pooling(name='pool1', stride=2, size=2))\n",
    "            self.add_layer(Convolutional(name='conv3', num_filters=64, stride=1, size=3, activation='relu'))\n",
    "            self.add_layer(Convolutional(name='conv4', num_filters=64, stride=1, size=3, activation='relu'))\n",
    "            self.add_layer(Pooling(name='pool2', stride=2, size=2))\n",
    "            self.add_layer(FullyConnected(name='fullyconnected', nodes1=64 * 5 * 5, nodes2=256, activation='relu'))\n",
    "            self.add_layer(Dense(name='dense', nodes=256, num_classes=10))\n",
    "\n",
    "    def forward(self, image, plot_feature_maps):                # forward propagate\n",
    "        for layer in self.layers:\n",
    "            if plot_feature_maps:\n",
    "                image = (image * 255)[0, :, :]\n",
    "                plot_sample(image, None, None)\n",
    "            image = layer.forward(image)\n",
    "        return image\n",
    "\n",
    "    def backward(self, gradient, learning_rate):                # backward propagate\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(gradient, learning_rate)\n",
    "\n",
    "    def train(self, dataset, num_epochs, learning_rate, validate, regularization, plot_weights, verbose):\n",
    "        history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print('\\n--- Epoch {0} ---'.format(epoch))\n",
    "            loss, tmp_loss, num_corr = 0, 0, 0\n",
    "            initial_time = time.time()\n",
    "            for i in range(len(dataset['train_images'])):\n",
    "                if i % 100 == 99:\n",
    "                    accuracy = (num_corr / (i + 1)) * 100       # compute training accuracy and loss up to iteration i\n",
    "                    loss = tmp_loss / (i + 1)\n",
    "\n",
    "                    history['loss'].append(loss)                # update history\n",
    "                    history['accuracy'].append(accuracy)\n",
    "\n",
    "                    if validate:\n",
    "                        indices = np.random.permutation(dataset['validation_images'].shape[0])\n",
    "                        val_loss, val_accuracy = self.evaluate(\n",
    "                            dataset['validation_images'][indices, :],\n",
    "                            dataset['validation_labels'][indices],\n",
    "                            regularization,\n",
    "                            plot_correct=0,\n",
    "                            plot_missclassified=0,\n",
    "                            plot_feature_maps=0,\n",
    "                            verbose=0\n",
    "                        )\n",
    "                        history['val_loss'].append(val_loss)\n",
    "                        history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "                        if verbose:\n",
    "                            print('[Step %05d]: Loss %02.3f | Accuracy: %02.3f | Time: %02.2f seconds | '\n",
    "                                  'Validation Loss %02.3f | Validation Accuracy: %02.3f' %\n",
    "                                  (i + 1, loss, accuracy, time.time() - initial_time, val_loss, val_accuracy))\n",
    "                    elif verbose:\n",
    "                        print('[Step %05d]: Loss %02.3f | Accuracy: %02.3f | Time: %02.2f seconds' %\n",
    "                              (i + 1, loss, accuracy, time.time() - initial_time))\n",
    "\n",
    "                    # restart time\n",
    "                    initial_time = time.time()\n",
    "\n",
    "                image = dataset['train_images'][i]\n",
    "                label = dataset['train_labels'][i]\n",
    "\n",
    "                tmp_output = self.forward(image, plot_feature_maps=0)       # forward propagation\n",
    "\n",
    "                # compute (regularized) cross-entropy and update loss\n",
    "                tmp_loss += regularized_cross_entropy(self.layers, regularization, tmp_output[label])\n",
    "\n",
    "                if np.argmax(tmp_output) == label:                          # update accuracy\n",
    "                    num_corr += 1\n",
    "\n",
    "                gradient = np.zeros(10)                                     # compute initial gradient\n",
    "                gradient[label] = -1 / tmp_output[label] + np.sum(\n",
    "                    [2 * regularization * np.sum(np.absolute(layer.get_weights())) for layer in self.layers])\n",
    "\n",
    "                learning_rate = lr_schedule(learning_rate, iteration=i)     # learning rate decay\n",
    "\n",
    "                self.backward(gradient, learning_rate)                      # backward propagation\n",
    "\n",
    "        if verbose:\n",
    "            print('Train Loss: %02.3f' % (history['loss'][-1]))\n",
    "            print('Train Accuracy: %02.3f' % (history['accuracy'][-1]))\n",
    "            plot_learning_curve(history['loss'])\n",
    "            plot_accuracy_curve(history['accuracy'], history['val_accuracy'])\n",
    "\n",
    "        if plot_weights:\n",
    "            for layer in self.layers:\n",
    "                if 'pool' not in layer.name:\n",
    "                    plot_histogram(layer.name, layer.get_weights())\n",
    "\n",
    "    def evaluate(self, X, y, regularization, plot_correct, plot_missclassified, plot_feature_maps, verbose):\n",
    "        loss, num_correct = 0, 0\n",
    "        for i in range(len(X)):\n",
    "            tmp_output = self.forward(X[i], plot_feature_maps)              # forward propagation\n",
    "\n",
    "            # compute cross-entropy update loss\n",
    "            loss += regularized_cross_entropy(self.layers, regularization, tmp_output[y[i]])\n",
    "\n",
    "            prediction = np.argmax(tmp_output)                              # update accuracy\n",
    "            if prediction == y[i]:\n",
    "                num_correct += 1\n",
    "                if plot_correct:                                            # plot correctly classified digit\n",
    "                    image = (X[i] * 255)[0, :, :]\n",
    "                    plot_sample(image, y[i], prediction)\n",
    "                    plot_correct = 1\n",
    "            else:\n",
    "                if plot_missclassified:                                     # plot missclassified digit\n",
    "                    image = (X[i] * 255)[0, :, :]\n",
    "                    plot_sample(image, y[i], prediction)\n",
    "                    plot_missclassified = 1\n",
    "\n",
    "        test_size = len(X)\n",
    "        accuracy = (num_correct / test_size) * 100\n",
    "        loss = loss / test_size\n",
    "        if verbose:\n",
    "            print('Test Loss: %02.3f' % loss)\n",
    "            print('Test Accuracy: %02.3f' % accuracy)\n",
    "        return loss, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3a18842cd88223d2eea50a134bb96e0584ccfa9a42436ff53b4efa05bbcefc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
